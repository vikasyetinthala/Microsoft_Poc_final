{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws= Workspace.create(name='Azureml-SDK-brillio',\n",
    "                     subscription_id=\"\",\n",
    "                     resource_group=\"\",\n",
    "                     create_resource_group=True,\n",
    "                     location=\"\")\n",
    "ws.write_config(path=\"./config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws=Workspace.from_config(\"./config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "az_store = Datastore.register_azure_blob_container(workspace=ws,\n",
    "                                                    datastore_name=\"azure_sdk_blob01\",\n",
    "                                                    account_name=\"\",\n",
    "                                                    container_name=\"\",\n",
    "                                                    account_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_store= Datastore.get(ws,\"azure_sdk_blob01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "csv_path= [(az_store,\"folder_name/file_name\")]\n",
    "dataset= Dataset.Tabular.from_delimited_files(path=csv_path)\n",
    "#register the dataset\n",
    "dataset = dataset.register(workspace=ws,\n",
    "                            name=\"\",\n",
    "                            create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_list=Workspace.list(subscription_id=\"\")\n",
    "ws_list=list(ws_list)\n",
    "az_default_store= ws.get_default_datastore()\n",
    "az_dataset=Dataset.get_by_name(ws,\"\")\n",
    "ds_list=list(ws.datasets.keys())\n",
    "for items in ds_list:\n",
    "    print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws=Workspace.from_config(\"./config\")\n",
    "az_store= Datastore.get(ws,\"azure_sdk_blob01\")\n",
    "az_dataset=Dataset.get_by_name(ws,\"\")\n",
    "az_default_store= ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= az_dataset.to_pandas_dataframe()\n",
    "df_sub=df[[\"col1\",\"col2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_ds_from_df = Dataset.Tabular.register_pandas_dataframe(dataframe=df_sub,\n",
    "                                                          target=az_store,\n",
    "                                                          name=\"datset name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list=[\"./data/test.csv\",\"./data/test1.csv\"]\n",
    "files_list= az_store.upload_files(files=files_list,\n",
    "                                   target_path=\"folder_name/\",\n",
    "                                relative_root=\"./data/\",\n",
    "                                overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_store.upload(src_dir=\"./data\",\n",
    "                target_path=\"folder_name/data\",\n",
    "                overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment=Experiment(workspace=ws,name=\"azureml_exp1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_run= experiment.start_logging()\n",
    "total_observations=len(df)\n",
    "null_df=df.isnull().sum()\n",
    "new_run.log(\"Total observations: \",total_observations)\n",
    "for columns in df.columns:\n",
    "    new_run.log(columns,nulldf[columns])\n",
    "new_run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running experiment with script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, ScriptRunConfig\n",
    "new_experiment=Experiment(workspace=ws,name=\"azureml_exp2\")\n",
    "script_config= ScriptRunConfig(source_directory=\".\",\n",
    "                               script=\"basicscript.py\")\n",
    "new_run = new_experiment.submit(config=script_config)\n",
    "new_run.wait_for_completion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating custom environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.environment import CondaDependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv= Environment(name=\"MyEnvironment\")\n",
    "myenv_dep= CondaDependencies.create(conda_packages=['scikit-learn'])\n",
    "myenv.python.conda_dependencies = myenv_dep\n",
    "myenv.register(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_config = ScriptRunConfig(source_directory=\".\",\n",
    "                                script=\"TrainingScript.py\",\n",
    "                                environment=myenv) \n",
    "new_run1 = new_experiment.submit(config=script_config)\n",
    "new_run1.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute \n",
    "cluster_name= \"vikascluster\"\n",
    "if cluster_name not in ws.compute_targets:\n",
    "    compute_config= AmlCompute.provisioning_configuration(vm_size=\"\",\n",
    "                                                        max_nodes=2)\n",
    "    cluster = AmlCompute.create(ws, cluster_name, compute_config)\n",
    "    cluster.wait_for_completion()\n",
    "else:\n",
    "    cluster= ws.compute_targets[cluster_name]\n",
    "print(cluster,\" compute cluster found.. using it....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "compute_cluster= ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "compute_cluster.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration \n",
    "run_config = RunConfiguration()\n",
    "run_config.target= compute_cluster \n",
    "run_config.environment = myenv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep \n",
    "from azureml.pipeline.core import PipelineData \n",
    "input_ds= ws.datasets.get(\"dataset name\")\n",
    "datafolder= PipelineData('datafolder', datastore=ws.get_default_datastore())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep_step= PythonScriptStep(name=\"Datapreparation\",\n",
    "                                source_directory=\".\",\n",
    "                                script_name= \"Dataprep_pipeline.py\",\n",
    "                                inputs=[input_ds.as_named_input('raw_data')],\n",
    "                                outputs=[datafolder],\n",
    "                                runconfig=run_config,\n",
    "                                arguments=['--datafolder', datafolder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step= PythonScriptStep(name=\"ModelTraining\",\n",
    "                             source_directory=\".\",\n",
    "                             script_name=\"Training_pipeline.py\",\n",
    "                             inputs=[datafolder],\n",
    "                             runconfig=run_config,\n",
    "                             arguments=['--datafolder',datafolder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps= [dataprep_step,train_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline \n",
    "new_pipeline = Pipeline(workspace=ws, steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_experiment= Experiment(workspace=ws, name=\"pipelineexp01\")\n",
    "pipeline_exp_run= new_experiment.submit(new_pipeline)\n",
    "pipeline_exp_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automl configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "automl_config= AutoMLConfig(task='classification',\n",
    "                            compute_target=cluster,\n",
    "                            training_data=input_ds,\n",
    "                            validation_size=0.3,\n",
    "                            label_column_name=\"\",\n",
    "                            primary_metric=\"norm_macro_recall\",\n",
    "                            iterations=10,\n",
    "                            max_concurrent_iterations=2,\n",
    "                            experiment_timeout_hours=0.25,\n",
    "                            featurization='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "new_exp= Experiment(ws,\"exp_name\")\n",
    "print(\"submitting the exxperiment\")\n",
    "new_run= new_exp.submit(automl_config)\n",
    "new_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_child_run= new_run.get_best_child()\n",
    "print(best_child_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in new_run.get_children():\n",
    "    print(\"run id: \",run.id)\n",
    "    print(\"accuracy is: \",run.get_metrics['accuracy'])\n",
    "    print(\"norm macro recall: \",run.get_metrics['norm_macro_recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv= Environment(name=\"MyEnvironment\")\n",
    "myenv_dep= CondaDependencies.create(conda_packages=['scikit-learn','pip'],\n",
    "                                    pip_packages=['azureml-defaults','azureml-interpret'])\n",
    "myenv.python.conda_dependencies = myenv_dep\n",
    "myenv.register(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute \n",
    "cluster_name= \"vikascluster\"\n",
    "if cluster_name not in ws.compute_targets:\n",
    "    compute_config= AmlCompute.provisioning_configuration(vm_size=\"\",\n",
    "                                                        max_nodes=2)\n",
    "    cluster = AmlCompute.create(ws, cluster_name, compute_config)\n",
    "    cluster.wait_for_completion()\n",
    "else:\n",
    "    cluster= ws.compute_targets[cluster_name]\n",
    "print(cluster,\" compute cluster found.. using it....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig \n",
    "script_config = ScriptRunConfig(source_directory=\".\",\n",
    "                                script=\"hyperdrivescript.py\",\n",
    "                                arguments=['--input-data',input_ds.as_named_input('raw_input')],\n",
    "                                environment=myenv,\n",
    "                                compute_target=cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import GridParameterSampling, choice\n",
    "hyper_params= GridParameterSampling(\n",
    "                                    {'--n_estimators': choice(10,20,30,100),\n",
    "                                    '--min_samples_leaf': choice(1,2,3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import HyperDriveConfig, PrimaryMetricGoal\n",
    "hyper_config = HyperDriveConfig(run_config=script_config,\n",
    "                                hyperparameter_sampling=hyper_params,\n",
    "                                policy=None,\n",
    "                                primary_metric_name='accuracy',\n",
    "                                primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                max_total_runs=20,\n",
    "                                max_concurrent_runs=2)\n",
    "from azureml.core.experiment import Experiment\n",
    "new_exp= Experiment(ws,\"exp_name\")\n",
    "print(\"submitting the exxperiment\")\n",
    "new_run= new_exp.submit(hyper_config)\n",
    "new_run.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = new_run.get_best_run_by_primary_metric() \n",
    "print(\"best run id: \",best_run.id)\n",
    "print(best_run.get_metrics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azureml-explain-model\n",
    "!pip install azureml-interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to write in any script\n",
    "from interpret.ext.blackbox import TabularExplainer\n",
    "classes=[\"\",\"\"]\n",
    "features = list(X.columns)\n",
    "tab_explainer = TabularExplainer(trained_model,\n",
    "                                x_train,\n",
    "                                features=features,\n",
    "                                classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_explanation= tab_explainer.explain_global(x_train)\n",
    "global_fi = global_explanation.get_feature_importance_dict()\n",
    "print(global_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_explain= x_test[0:5]\n",
    "local_explanation=tab_explainer.explain_local(x_explain)\n",
    "local_features= local_explanation.get_ranked_local_names()\n",
    "local_importance = local_explanation.get_ranked_local_values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.interpret import ExplanationClient \n",
    "explain_client.upload_model_explanation(global_explanation,comment=\"My First Explanation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws= Workspace.from_config(\"./config\")\n",
    "new_run= ws.get_run(\"run id\")\n",
    "explain_client = ExplanationClient.from_run(new_run)\n",
    "downloaded_explanation = explain_client.download_model_explanation()\n",
    "feature_importances=downloaded_explanation.get_feature_importance_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Model\n",
    "ws= Workspace.from_config(\"./config\")\n",
    "new_run= ws.get_run(\"run id\")\n",
    "new_run.register_model(model_path='outputs/models.pkl',\n",
    "                        model_name='vikasmodel',\n",
    "                        tags={'source':'sdk-run','algorithm':'Randomforest'},\n",
    "                        properties={'Accuracy':new_run.get_metrics()['accuracy']},\n",
    "                        description=\"combined models from the run\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying all models from registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=Model.list(ws)\n",
    "for model in Model.list(ws):\n",
    "    print(\"\\n\",model.name, 'version: ',model.version)\n",
    "    print(\"model run id \",model.run_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diploying the model in Kubernetes service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "cluster_name= 'aks-cluster-vikas'\n",
    "aks_config = AksCompute.provisioning_configuration(location='region_name',\n",
    "                                                    vm_size='name',\n",
    "                                                    agent_count=1,\n",
    "                                                    cluster_purpose='Dev/Test')\n",
    "production_cluster= ComputeTarget.create(ws, cluster_name, aks_config)\n",
    "production_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "infernece_config = InferenceConfig(environment=myenv,\n",
    "                                    entry_script='scoring_script.py',\n",
    "                                    source_directory='./service_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "deploy_config = AksWebservice.deploy_configuration(cpu_cores=1,memory_gb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ws.models['model_name']\n",
    "service = Model.deploy(workspace=ws,\n",
    "                        name='model-service',\n",
    "                        models=[model],\n",
    "                        inference_config=infernece_config,\n",
    "                        deployment_config=deploy_config,\n",
    "                        deployment_target=production_cluster)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12e513a353d39af38cd2cc5b714de99c83b57fbf4ce718c7286e787d92a207bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
